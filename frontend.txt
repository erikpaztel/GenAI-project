import streamlit as st
import random
import time


# --- Page Configuration ---
st.set_page_config(
   page_title="RAG Document Q&A System",
   page_icon="ðŸ“„",
   layout="wide"
)


# --- Initialize Session State ---
# This should be done at the top to ensure all keys are set from the start.
if "messages" not in st.session_state:
   st.session_state.messages = [{"role": "assistant", "content": "Hello! Upload a document and ask me anything about it. ðŸ“„"}]
if "document_processed" not in st.session_state:
   st.session_state.document_processed = False


# --- Sidebar for Document Upload ---
with st.sidebar:
   st.header("Upload Document")
   uploaded_file = st.file_uploader(
       "Upload a PDF or TXT file",
       type=["pdf", "txt"],
       accept_multiple_files=False
   )


   if uploaded_file:
       st.success(f"File '{uploaded_file.name}' uploaded successfully!")
       if st.button("Process Document"):
           with st.spinner("Processing document..."):
               # Placeholder for the actual ingestion logic
               time.sleep(2)
               st.success("Document processed!")
               st.session_state.document_processed = True
   else:
       # Reset the state if no file is uploaded
       st.session_state.document_processed = False
       st.info("Please upload a file to begin.")




# --- Main Chat Interface ---
st.title("RAG Document Q&A System")


# Display chat messages from history
for message in st.session_state.messages:
   with st.chat_message(message["role"]):
       st.markdown(message["content"])
       # Display sources if they exist in the message
       if "sources" in message:
           with st.expander("View Sources"):
               for source in message["sources"]:
                   st.write(source)


# Accept user input. The input is disabled if no document has been processed.
prompt = st.chat_input(
   "Ask a question about your document...",
   disabled=not st.session_state.document_processed
)


if prompt:
   st.session_state.messages.append({"role": "user", "content": prompt})
   with st.chat_message("user"):
       st.markdown(prompt)


   # Display assistant response
   with st.chat_message("assistant"):
       message_placeholder = st.empty()
       full_response = ""
       # Mock response for demonstration
       assistant_response = "This is a mock answer based on the document's content."
      
       # Simulate stream of response
       for chunk in assistant_response.split():
           full_response += chunk + " "
           time.sleep(0.05)
           message_placeholder.markdown(full_response + "â–Œ")
      
       message_placeholder.markdown(full_response)


       # NEW: Add an expandable section for sources
       with st.expander("View Sources"):
           # This is a placeholder for the actual source chunks
           st.write("Source 1: 'The first relevant chunk of text from the document...'")
           st.write("Source 2: 'Another relevant paragraph that contributed to the answer...'")
      
       # We will create a list of sources to append to the message history
       mock_sources = [
           "Source 1: 'The first relevant chunk of text from the document...'",
           "Source 2: 'Another relevant paragraph that contributed to the answer...'"
       ]


   # Add assistant response and sources to chat history
   st.session_state.messages.append({
       "role": "assistant",
       "content": full_response,
       "sources": mock_sources
   })
